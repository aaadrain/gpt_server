# 后台启动 nohup sh start.sh > gptserver.log &
# openai_api_server
serve_args:
  host: 0.0.0.0
  port: 8082
  controller_address: http://localhost:21001
  # api_keys: 111,222

# controller
controller_args:
  host: 0.0.0.0
  port: 21001
  dispatch_method: shortest_queue # lottery shortest_queue

# model worker
model_worker_args:
  host: 0.0.0.0
  controller_address: http://localhost:21001

models:
- internvl2: #自定义的模型名称
    alias: null # 别名     例如  gpt4,gpt3
    enable: false # false true
    model_config:
      model_name_or_path: /home/dev/model/OpenGVLab/InternVL2-40B-AWQ/
      enable_prefix_caching: false
    model_type: internvl2 # qwen  yi internlm
    work_mode: lmdeploy-turbomind # vllm hf lmdeploy-turbomind  lmdeploy-pytorch
    device: gpu # gpu / cpu
    workers:
    - gpus:
      # - 1
      - 0
      # - gpus:
      #   - 0

- qwen: #自定义的模型名称
    alias: gpt-4,gpt-3.5-turbo,gpt-3.5-turbo-16k # 别名     例如  gpt4,gpt3
    enable: false # false true
    model_config:
      model_name_or_path: /home/dev/model/qwen/Qwen2___5-7B-Instruct/
      enable_prefix_caching: true
      dtype: auto
      max_model_len: 65536
      # lora:
      #   test_lora: /home/dev/project/LLaMA-Factory/saves/Qwen1.5-14B-Chat/lora/train_2024-03-22-09-01-32/checkpoint-100

    model_type: qwen # qwen  yi internlm
    work_mode: lmdeploy-turbomind # vllm hf lmdeploy-turbomind  lmdeploy-pytorch

    device: gpu # gpu / cpu
    workers:
    - gpus:
      - 1
      # - gpus:
      #   - 3

- bge-reranker-base:
    alias: null # 别名   
    enable: true # false true
    model_config:
      model_name_or_path: /home/dev/model/Xorbits/bge-reranker-base/
    model_type: embedding_infinity # embedding_infinity
    work_mode: hf
    device: gpu # gpu / cpu
    workers:
    - gpus:
      - 2
- acge_text_embedding:
    alias: text-embedding-ada-002 # 别名   
    enable: true # false true
    model_config:
      model_name_or_path: /home/dev/model/aspire/acge_text_embedding
    model_type: embedding_infinity # embedding_infinity
    work_mode: hf
    device: gpu # gpu / cpu
    workers:
    - gpus:
      - 2







